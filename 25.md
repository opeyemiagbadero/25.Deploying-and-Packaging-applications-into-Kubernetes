Deploy Jfrog Artifactory into Kubernetes. The best approach to easily get Artifactory into kubernetes is to use helm.

Search for an official helm chart for Artifactory on Artifact Hub

![1  Search for an official helm chart for artifactory on artifact hub](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/ca426dc6-bd75-4759-a071-2ff25e1f6ffb)
click on see all result and select an official image and choose the first option from the result. Review the Artifactory page and click on the install menu on the right to see the installation commands.

![2  REview the artifactory page and click on the install menu to see the installation commands](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/d906f579-5155-46cc-9865-af5b65e43cd5)

Add the jfrog remote repository on your local machine `helm repo add jfrog https://charts.jfrog.io`

Create a namespace called tools where all the tools for DevOps will be deployed. `kubectl create ns tools`

Update the helm repo index on your laptop/computer `helm repo update`

Install  artifactory `helm upgrade --install artifactory jfrog/artifactory --version 107.33.12 -n tools`

![3  Add the jfrog repository on your local machine, create a namespace called tools, update the helms repo and install artifactory](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/8144a817-21cd-42e8-af00-1df3f761dba1)

```
Release "artifactory" does not exist. Installing it now.
NAME: artifactory
LAST DEPLOYED: Sat May 28 09:26:08 2022
NAMESPACE: tools
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Congratulations. You have just deployed JFrog Artifactory!

1. Get the Artifactory URL by running these commands:

   NOTE: It may take a few minutes for the LoadBalancer IP to be available.
         You can watch the status of the service by running 'kubectl get svc --namespace tools -w artifactory-artifactory-nginx'
   export SERVICE_IP=$(kubectl get svc --namespace tools artifactory-artifactory-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
   echo http://$SERVICE_IP/

2. Open Artifactory in your browser
   Default credential for Artifactory:
   user: admin
   password: password
   ```
   
 The artifactory helm chart comes bundled with the Artifactory software, a PostgreSQL database and an Nginx proxy which it uses to configure routes to the different capabilities of Artifactory. Getting the pods after some time, you should see something like the below.
 
![4 1 Runn the command kubectl get pods -n tools](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/9cfe6d72-0a46-48a7-995c-3e40fbdf9900)

Each of the deployed application have their respective services. This is how you will be able to reach either of them. 

![5 Each of the deployed apps have thier res  command to see thempective services   RUn kubectl get svc -n tools](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/86badca8-735e-43fa-b165-e6f0f9047ef2)

Notice that, the Nginx Proxy has been configured to use the service type of LoadBalancer. Therefore, to reach Artifactory, we will need to go through the Nginx proxy’s service. Which happens to be a load balancer created in the cloud provider. 

Run the kubectl command to retrieve the Load Balancer URL. `kubectl get svc artifactory-artifactory-nginx -n tools`

![6  Run the kubectl get svc my-artifactory-artifactory-nginx -n tools command to get load balancer url](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/820822d4-607a-4f82-ac9f-c01e5e160f3b)

Copy the URL and paste in the browser 

![7  copy the URL and paste in the browser](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/757a77d2-aa52-4f58-8426-be34710674ba)

Login using the default username and password

![8  Log in using the dfault username and passwrod given](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/c5d99a80-5d87-4791-9f25-ba6d786c978b)


How the Nginx URL for Artifactory is configured in Kubernetes?
Without clicking further on the Get Started page, lets dig a bit more into Kubernetes and Helm. How did Helm configure the URL in kubernetes?

Helm uses the values.yaml file to set every single configuration that the chart has the capability to configure. THe best place to get started with an off the shelve chart from artifacthub.io is to get familiar with the DEFAULT VALUES

click on the DEFAULT VALUES section on Artifact hub 
![9  click on the default values section on Artifacft hub](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/76092dd6-b569-4272-bae4-6f3de6d28c93)

Here you can search for key and value pairs 

![10 Here you can search for key and value pairs e g  type ngnix in the search bar](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/aac5a7b0-34c9-4078-b49f-adc8dc298089)

For example, when you type nginx in the search bar, it shows all the configured options for the nginx proxy. 

![11  click on nginx enabled](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/521e8c6e-8f2c-46ad-b183-37ec7abaead9)

selecting nginx.enabled from the list will take you directly to the configuration in the YAML file. 

![12  selecting the ngninx enabled from the list will tale you directly to the configuration in the YAML file](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/08b3b094-7cad-4688-baff-ed7e7bf4db37)

Search for nginx.service and select nginx.service.type. You will see the confired type of Kubernetes service for Nginx. As you can see, it is LoadBalancer by default. To work directly with the values.yaml file, you can download the file locally by clicking on the download icon. 

![13  search for nginx service and select nginx service type You will see the confirmed type of kunernetes service for nginx, which is a loadbalancer by default](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/cecd239d-7920-4b3e-9f7e-97bf2595c6bd)


# Is the Load Balancer Service type the Ideal configuration option to use in the Real World? #

Setting the service type to Load Balancer is the easiest way to get started with exposing applications running in kubernetes externally. But provisioning load balancers for each application can become very expensive over time, and more difficult to manage. Especially when tens or even hundreds of applications are deployed.

The best approach is to use Kubernetes Ingress instead. But to do that, we will have to deploy an Ingress Controller.

A huge benefit of using the ingress controller is that we will be able to use a single load balancer for different applications we deploy. Therefore, Artifactory and any other tools can reuse the same load balancer. Which reduces cloud cost, and overhead of managing multiple load balancers. more on that later.

For now, we will leave Artifactory, move on to the next phase of configuration (Ingress, DNS(Route53) and Cert Manager), and then return to Artifactory to complete the setup so that it can serve as a private docker registry and repository for private helm charts.


# Deploying Ingress COntroller and Managing Ingress Resources. #

Before we discuss what ingress controllers are, it will be important to start off understanding about the Ingress resource.

An ingress is an API object that manages external access to the services in a kubernetes cluster. It is capable to provide load balancing, SSL termination and name-based virtual hosting. In otherwords, Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource.


An ingress resource for Artifactory would like like below

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: artifactory
spec:
  ingressClassName: nginx
  rules:
  - host: "tooling.artifactory.sandbox.svc.darey.io"
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: artifactory
            port:
              number: 8082
```

- An Ingress needs apiVersion, kind, metadata and spec fields
- The name of an Ingress object must be a valid DNS subdomain name
- Ingress frequently uses annotations to configure some options depending on the Ingress controller.
- Different Ingress controllers support different annotations. Therefore it is important to be up to date with the ingress controller’s specific documentation to     know what annotations are supported.
- It is recommended to always specify the ingress class name with the spec ingressClassName: nginx. This is how the Ingress controller is selected, especially when   there are multiple configured ingress controllers in the cluster.
- The domain darey.io should be replaced with your own domain.


# Ingress controller #

If you deploy the yaml configuration specified for the ingress resource without an ingress controller, it will not work. In order for the Ingress resource to work, the cluster must have an ingress controller running.

Unlike other types of controllers which run as part of the kube-controller-manager. Such as the Node Controller, Replica Controller, Deployment Controller, Job Controller, or Cloud Controller. Ingress controllers are not started automatically with the cluster.

Kubernetes as a project supports and maintains AWS, GCE, and NGINX ingress controllers.

It is possible to deploy any number of ingress controllers in the same cluster. That is the essence of an ingress class. By specifying the spec ingressClassName field on the ingress object, the appropriate ingress controller will be used by the ingress resource.

Lets get into action and see how all of these fits together.

# Deploy Nginx Ingress Controller #

On this project, we will deploy and use the Nginx Ingress Controller. It is always the default choice when starting with Kubernetes projects. It is reliable and easy to use.

Since this controller is maintained by Kubernetes, there is an official guide the installation process. Hence, we wont be using artifacthub.io here. Even though you can still find ready to go charts there, it just makes sense to always use the official guide in this scenario.

Using the Helm approach, according to the official guide;

1. Install Nginx Ingress Controller in the ingress-nginx namespace
```
helm upgrade --install ingress-nginx ingress-nginx \
--repo https://kubernetes.github.io/ingress-nginx \
--namespace ingress-nginx --create-namespace
```
This command is idempotent: if the ingress controller is not installed, it will install it, if the ingress controller is already installed, it will upgrade it.

![14  INstall the Helm approach according the official guide](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/3a3b8a49-d972-4f5e-a4f7-d9d22d3782c7)


2. A few pods should start in the ingress-nginx namespace: `kubectl get pods --namespace=ingress-nginx`
3. After a while, they should all be running. The following command will wait for the ingress controller pod to be up, running, and ready: 
```
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=120s
  ```
4. Check to see the created load balancer in AWS. `kubectl get service -n ingress-nginx`
   FInd the ouptut of the command in the screenshot below

![15  A few pods should start in the ngress-ngnixn  namespace by runnign the kubectl get pods   command   - 4  check to see the created load balncers in AWS](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/6da3a258-da61-4b7a-a11e-fe016f0aa5d0)

The ingress-nginx-controller service that was created is of the type LoadBalancer. That will be the load balancer to be used by all applications which require external access, and is using this ingress controller.If you go ahead to AWS console, copy the address in the EXTERNAL-IP column, and search for the loadbalancer, you will see an output like below.

![16  go ahead to AWS console, copy the address in the EXTERNAL IP column and search for the loadbalancer](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/8021432d-3083-4358-b8a0-277da6e92cfc)


5. Check the IngressClass that identifies this ingress controller. `kubectl get ingressclass -n ingress-nginx`

![17  check the ingressclass that identifies this ingress controller](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/523701b1-6605-41fe-93d2-14f8924856c7)


# Deploy Artifactory Ingress #

Configure the ingress so that we can route traffic to the Artifactory internal service, through the ingress controller’s load balancer.

```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: artifactory
spec:
  ingressClassName: nginx
  rules:
  - host: "tooling.artifactory.sandbox.svc.lami.land"
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: my-artifactory
            port:
              number: 8082
```              
Run the command `kubectl apply -f ingress.yaml -n tools` and `kubectl get ingress -n tools` which gives an output showing the 
the:
CLASS – The nginx controller class name - nginx
HOSTS – The hostname to be used in the browser tooling.artifactory.sandbox.svc.lami.land
ADDRESS – The loadbalancer address that was created by the ingress controller

# Configure DNS #

In the create record section, type in the record name, and toggle the alias button to enable an alias. An alias is of the A DNS record type which basically routes directly to the load balancer. In the choose endpoint bar, select Alias to Application and Classic Load BalancerSelect the region and the load balancer required. You will not need to type in the load balancer, as it will already populate.

![18  AWS Alias Method](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/7f83c5ac-c14e-467f-a128-b0d193cf397f)

# Visiting the application from the browser #

So far, we now have an application running in Kubernetes that is also accessible externally. That means if you navigate to https://tooling.artifactory.sandbox.svc.lami.land/. it should load up the artifactory application. 







Click on the padlock sign on the browser, which shows that the certificate in not valid. You will see the details of the certificate. There you can confitm that there is an encryption configured for the traffic, but the browser is just not cool with it

![19 Visiting the application from the browser  click on the Not secure part of the browser](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/645a8d2f-ec46-478a-a757-7f92965f3654)


# Explore Artifactory Web UI #
Now that we can access the application externally, although insecure, its time to login for some exploration. Afterwards we will make it a lot more secure and access our web application on any browser.

Insert the username and password to load the Get started page, reset the admin password. activate the artifactory licence and set the base URL using https. Skip the proxy settings and the creation of repositories and finish up the setup.

![26](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/d6b0a772-f233-41eb-9f4e-9c68f1cce27b)

![26a Congratulations page](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/3cf47f37-260a-4cfb-a202-ebb4e0bf61d7)

![27](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/b668d7d8-30cf-4121-97a7-787a9b0122cb)


# Deploy Cert-manager #

Find the cert-manager helm chart in the Artifact Hub, follow the installation guide and deploy into kubernetes.



![28  Deploying cert-manager OUTPUT](https://github.com/opeyemiagbadero/25.Deploying-and-Packaging-applications-into-Kubernetes/assets/79456052/c9d55270-c46a-4606-aa40-ee33348f2f18)

Create a certificate issuer manifest  with a cluster issuer so that it can ge scoped globally.











